(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{265:function(t,s,a){t.exports=a.p+"assets/img/urk_scaling.1f27c164.jpg"},266:function(t,s,a){t.exports=a.p+"assets/img/urk.e6564348.jpg"},267:function(t,s,a){t.exports=a.p+"assets/img/pellworm_248.29ad280d.jpg"},268:function(t,s,a){t.exports=a.p+"assets/img/pellworm_ndvi.36c775d8.jpg"},269:function(t,s,a){t.exports=a.p+"assets/img/pellworm_threshold.be97c121.jpg"},270:function(t,s,a){t.exports=a.p+"assets/img/pellworm_s1.acf74ce7.jpg"},271:function(t,s,a){t.exports=a.p+"assets/img/pellworm_kernels.d12dda41.jpg"},399:function(t,s,a){"use strict";a.r(s);var n=a(4),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"openeo-cookbook"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#openeo-cookbook"}},[t._v("#")]),t._v(" OpenEO Cookbook")]),t._v(" "),n("p",[t._v("This is the openEO cookbook that you can refer to to get a first idea on how to solve problems with openEO in the three client languages Python, R and JavaScript. It describes how to implement simple use cases in a pragmatic way.")]),t._v(" "),n("p",[t._v("Please refer to the getting started guides for "),n("RouterLink",{attrs:{to:"/documentation/1.0/javascript/"}},[t._v("JavaScript")]),t._v(", "),n("RouterLink",{attrs:{to:"/documentation/1.0/python/"}},[t._v("Python")]),t._v(" and "),n("RouterLink",{attrs:{to:"/documentation/1.0/r/"}},[t._v("R")]),t._v(" if you have never worked with one of the openEO client libraries before. This guide requires you to have a basic idea of how to establish a connection to a back-end and how to explore that back-end.")],1),t._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[t._v("References")]),t._v(" "),n("ul",[n("li",[n("RouterLink",{attrs:{to:"/documentation/1.0/processes.html"}},[t._v("openEO processes documentation")])],1),t._v(" "),n("li",[n("a",{attrs:{href:"https://hub.openeo.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("openEO Hub"),n("OutboundLink")],1),t._v(" to discover back-ends with available data and processes")]),t._v(" "),n("li",[n("a",{attrs:{href:"https://editor.openeo.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("openEO Web Editor"),n("OutboundLink")],1),t._v(" to visually build and execute processing workflows")])]),t._v(" "),n("hr"),t._v(" "),n("ul",[n("li",[n("a",{attrs:{href:"https://open-eo.github.io/openeo-python-client/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Python client documentation"),n("OutboundLink")],1)]),t._v(" "),n("li",[n("a",{attrs:{href:"https://open-eo.github.io/openeo-js-client/2.0.0/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("JavaScript client documentation"),n("OutboundLink")],1)])])]),t._v(" "),n("h2",{attrs:{id:"chapter-1"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#chapter-1"}},[t._v("#")]),t._v(" Chapter 1")]),t._v(" "),n("p",[t._v("In this chapter, we want to explore the different output formats that are possible with openEO. For that, we load and filter a collection (a datacube) of satellite data and calculate the temporal mean of that data. Different steps (e.g. a linear scaling) are done to prepare for the data to be output in one of the formats: Raster or text data.")]),t._v(" "),n("p",[t._v("Throughout this guide, code examples for all three client languages are given. Select your preferred language with the code switcher on the right-hand side to set all examples to that language.")]),t._v(" "),n("h3",{attrs:{id:"connecting-to-a-back-end"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#connecting-to-a-back-end"}},[t._v("#")]),t._v(" Connecting to a back-end")]),t._v(" "),n("p",[t._v("Click the link below to see how to connect to a back-end (via OpenID Connect). You can call the connection object "),n("code",[t._v("con")]),t._v(" as it is done in all following code, to avoid confusion throughout the rest of the tutorials.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("p",[n("RouterLink",{attrs:{to:"/documentation/1.0/python/#openid-connect-authentication"}},[t._v("Getting started: Authentication")])],1)]},proxy:!0},{key:"r",fn:function(){return[n("p",[n("RouterLink",{attrs:{to:"/documentation/1.0/r/#openid-connect-authentication"}},[t._v("Getting started: Authentication")])],1)]},proxy:!0},{key:"js",fn:function(){return[n("p",[n("RouterLink",{attrs:{to:"/documentation/1.0/javascript/#openid-connect-authentication"}},[t._v("Getting started: Authentication")])],1)]},proxy:!0}])}),t._v(" "),n("p",[t._v("In R and JavaScript it is very useful to assign a graph-building helper object to a variable, to easily access all openEO processes and add them to the process graph that you will be building. These objects will be used throughout this guide. In Python, it also helps to import a helper object, even though we'll need it less often.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# import ProcessBuilder functions")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" openeo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("processes "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ProcessBuilder\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" Many functions in "),n("em",[t._v("child processes")]),t._v(" (see below), are instances of this "),n("code",[t._v("ProcessBuilder")]),t._v(" import.")])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# assign the graph-building helper object to "p" for easy access to all openEO processes, see > ?processes()')]),t._v("\np "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" processes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" In all R code, "),n("code",[t._v("p")]),t._v(" is used to select openEO processes.")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// assign the graph-building helper object to "builder" for easy access to all openEO processes')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" builder "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("buildProcess")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" In all JavaScript code, "),n("code",[t._v("builder")]),t._v(" is used to select openEO processes.")])]},proxy:!0}])}),t._v(" "),n("h3",{attrs:{id:"input-load-collection"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#input-load-collection"}},[t._v("#")]),t._v(" Input: "),n("code",[t._v("load_collection")])]),t._v(" "),n("p",[t._v("Before loading a collection, we need to find out the exact name of a collection we want to use (back-end-specific, see references "),n("a",{attrs:{href:"#openeo-cookbook"}},[t._v("at the top")]),t._v("). We assign the spatial and temporal extent to variables, so that we can re-use them on other collections we might want to load. Let's look for a Sentinel 2 (preprocessed level 2A preferably) collection and load the green, red and a near-infrared band (bands 3, 4 and 8).")]),t._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[t._v("Collection and Band Names")]),t._v(" "),n("p",[t._v("The names of collections and bands differ between back-ends. So always check the collection description for the correct names. The differences might be subtle, e.g. "),n("code",[t._v("B8")]),t._v(" vs. "),n("code",[t._v("B08")]),t._v(".")])]),t._v(" "),n("p",[t._v("We'll name our collection very explicitly "),n("code",[t._v("cube_s2_b348")]),t._v(" as to not get confused later on.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# make dictionary, containing bounding box")]),t._v("\nurk "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"west"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.5661")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"south"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6457")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"east"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.7298")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"north"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.7335")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# make list, containing the temporal interval")]),t._v("\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-04-26"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-04-30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load first datacube")]),t._v("\ncube_s2_b348 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_collection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"COPERNICUS/S2_SR"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    spatial_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urk"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    temporal_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    bands "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create variables for loading collection")]),t._v("\nurk "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("west "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.5661")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" south "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6457")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" east "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.7298")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" north "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.7335")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-04-26"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-04-30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load first datacube")]),t._v("\ncube_s2_b348 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("load_collection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  id "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"COPERNICUS/S2_SR"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  spatial_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urk"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  temporal_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  bands"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// make spatial and temporal extent")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" urk "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"west"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.5661")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"south"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6457")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"east"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.7298")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"north"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.7335")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" t "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-04-26"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-04-30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("   \n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// load first cube")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_b348 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("load_collection")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"COPERNICUS/S2_SR"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    urk"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" JavaScript doesn't use parameter names (like Python and R), so the parameters need to be in the order that they are defined in the "),n("RouterLink",{attrs:{to:"/documentation/1.0/processes.html"}},[t._v("openEO processes documentation")]),t._v(".")],1)]},proxy:!0}])}),t._v(" "),n("h3",{attrs:{id:"filter-bands-filter-bands"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#filter-bands-filter-bands"}},[t._v("#")]),t._v(" Filter Bands: "),n("code",[t._v("filter_bands")])]),t._v(" "),n("p",[t._v("To go through the desired output formats, we'll need one collection with three bands, and one collection with only one band. Here we use "),n("code",[t._v("filter_bands")]),t._v(", when of course we could also just define a separate collection via "),n("code",[t._v("load_collection")]),t._v(". As our input datacube already has the required three bands, we filter it for a single band to create an additional datacube with the same spatial and temporal extent, but with only one band (band 8).")]),t._v(" "),n("p",[t._v("We'll name this one "),n("code",[t._v("cube_s2_b8")]),t._v(" to distinguish it from the original "),n("code",[t._v("cube_s2_b348")]),t._v(".")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# filter for band 8")]),t._v("\ncube_s2_b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter_bands"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bands "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# filter for band 8")]),t._v("\ncube_s2_b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("filter_bands"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bands "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// filter for band 8")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter_bands")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b348"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("h3",{attrs:{id:"temporal-mean-reduce-dimension"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#temporal-mean-reduce-dimension"}},[t._v("#")]),t._v(" Temporal Mean: "),n("code",[t._v("reduce_dimension")])]),t._v(" "),n("p",[t._v("As we don't want to download the raw collection of satellite data, we need to reduce that data somehow. That means, we want to get rid of one dimension. Let's say we calculate a "),n("code",[t._v("mean")]),t._v(" over all timesteps, and then drop the temporal dimension (as it's empty then anyway, see explanation in the "),n("RouterLink",{attrs:{to:"/documentation/1.0/datacubes.html#reduce"}},[t._v("datacube guide")]),t._v("). This can be done via "),n("code",[t._v("reduce_dimension()")]),t._v(". The function requires a reducer, in our case a "),n("code",[t._v("mean")]),t._v(" process, and the dimension over which to reduce, given as a string ("),n("code",[t._v('"t"')]),t._v(").")],1),t._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[t._v("Child Processes")]),t._v(" "),n("p",[t._v("Here, we need to define a child process: A function that is called by (or passed to) another function, and then works on a subset of the datacube (somewhat similar to the concept of callbacks in JavaScript). In this case: We want "),n("code",[t._v("reduce_dimension")]),t._v(" to use the "),n("code",[t._v("mean")]),t._v(" function to average all timesteps of each pixel. Not any function can be used like this, it must be defined by openEO, of course.")]),t._v(" "),n("p",[t._v("All clients have more or less different specifics when defining a child process. As you can observe directly below, one way to define one is to define the function directly inside the parent process.")]),t._v(" "),n("p",[t._v("For a more clean way to define a child process, see the chapter below.")])]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# reduce all timesteps")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mean_time() is a shortcut function")]),t._v("\ncube_s2_b8_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean_time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# alternatively, 'reduce_dimension' can be used")]),t._v("\ncube_s2_b8_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# additionally, reduce second collection")]),t._v("\ncube_s2_b348_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean_time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" In python, the child process can be a string.")])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# reduce dimension, first collection")]),t._v("\ncube_s2_b8_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# reduce, second collection")]),t._v("\ncube_s2_b348_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" In R, we can select a child process from the "),n("code",[t._v("p")]),t._v(" helper object.")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// reduce dimension")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_b8_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mean")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// second collection")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_b348_red "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b348"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mean")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" In JavaScript, arrow functions can be used as child processes.")])]},proxy:!0}])}),t._v(" "),n("h3",{attrs:{id:"scale-all-pixels-linearly-apply-linear-scale-range"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#scale-all-pixels-linearly-apply-linear-scale-range"}},[t._v("#")]),t._v(" Scale All Pixels Linearly: "),n("code",[t._v("apply")]),t._v(", "),n("code",[t._v("linear_scale_range")])]),t._v(" "),n("p",[t._v("To create a PNG output, we need to scale the satellite data we have down to the 8bit range of a PNG image. For this, the scale range of our imagery has to be known. For Sentinel 2 over urban and agricultural areas, we can use "),n("code",[t._v("6000")]),t._v(" as a maximum.")]),t._v(" "),n("p",[t._v("We'll use the process "),n("code",[t._v("linear_scale_range")]),t._v(". It takes a number and the four borders of the intervals as input. Because it works on a number and not a datacube as all processes discussed so far, we need to nest the process into an "),n("code",[t._v("apply")]),t._v(", once again defining a child process. "),n("code",[t._v("apply")]),t._v(" applies a unary process to all pixels of a datacube.")]),t._v(" "),n("p",[t._v("This time we'll also define our child processes externally, as to not get confused in too much code nesting.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define child process, use ProcessBuilder")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scale_function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ProcessBuilder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_scale_range"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# apply scale_function to all pixels")]),t._v("\ncube_s2_b348_red_lin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348_red"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scale_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Resource:")]),t._v(" Refer to the "),n("a",{attrs:{href:"https://open-eo.github.io/openeo-python-client/processes.html#processes-with-child-callbacks",target:"_blank",rel:"noopener noreferrer"}},[t._v("Python client documentation"),n("OutboundLink")],1),t._v(" to learn more about child processes in Python.")])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define child process")]),t._v("\nscale_function "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("linear_scale_range"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inputMin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inputMax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" outputMin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" outputMax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# apply scale range to all pixels")]),t._v("\ncube_s2_b348_red_lin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348_red"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" process "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scale_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// define child process (long way)")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("scale_function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("linear_scale_range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// we could also use an arrow function here to abbreviate")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// var scale_function = (x, context, child) => child.linear_scale_range(x, 0, 6000, 0, 255)")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// apply child process to all pixels")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_b348_red_lin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("builder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b348_red"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scale_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" Given the two ways of defining a child process above, we can see that in the long way, the builder is available as "),n("code",[t._v("this")]),t._v(", while in arrow functions, it has to be passed as the last argument (here called "),n("code",[t._v("child")]),t._v(").")])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(265),alt:"A comparison between an unscaled and a scaled raster is shown. Unscaled values are much larger, sclaed values much closer together and all below 255."}}),t._v(" "),n("figcaption",[t._v("A part of our original image is displayed here, to observe the effect of applying a linear scale: Original (thus unscaled) imagery is seen on the left, and scaled values on the right.")])]),t._v(" "),n("h3",{attrs:{id:"spatial-aggregation-aggregate-spatial"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spatial-aggregation-aggregate-spatial"}},[t._v("#")]),t._v(" Spatial Aggregation: "),n("code",[t._v("aggregate_spatial")])]),t._v(" "),n("p",[t._v('To look at text output formats we first need to "de-spatialize" our data. Or put another way: If we\'re interested in e.g. timeseries of various geometries, text output might be very interesting for us.')]),t._v(" "),n("p",[t._v("To aggregate over certain geometries, we use the process "),n("code",[t._v("aggregate_spatial")]),t._v(". It takes valid GeoJSON as input. We can pass a GeoJSON "),n("code",[t._v("FeatureCollection")]),t._v(" in Python and JavaScript, but we need to introduce two packages in R, "),n("code",[t._v("sf")]),t._v(" and "),n("code",[t._v("geojsonsf")]),t._v(", to convert the "),n("code",[t._v("FeatureCollection")]),t._v(" "),n("code",[t._v("string")]),t._v(" to a "),n("code",[t._v("simple feature collection")]),t._v(".")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# polygons as (geojson) dict")]),t._v("\npolygons "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FeatureCollection"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"features"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Feature"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"geometry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Polygon"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"coordinates"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.636715888977051")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6807532675943")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.629441738128662")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68157281641395")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.633561611175536")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.67787822078012")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.636715888977051")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6807532675943")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Feature"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"geometry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Polygon"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"coordinates"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.622982978820801")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68595649102906")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.6201934814453125")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68429152697491")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.628776550292969")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.683719180920846")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.622982978820801")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68595649102906")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# aggregate spatial")]),t._v("\ncube_s2_b8_agg "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("aggregate_spatial"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("geometries "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" polygons"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# alternatively, the python client has a shortcut function for this special case")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cube_s2_b8_agg = cube_s2_b8.polygonal_mean_timeseries(polygon = polygons)")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load sf and geojsonsf")]),t._v("\nlibrary"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlibrary"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("geojsonsf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create string containing the geojson FeatureCollection")]),t._v("\npolygons_string "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('\'{ "type": "FeatureCollection", "features": [ { "type": "Feature", "properties": {}, "geometry": { "type": "Polygon", "coordinates": [ [ [ 5.636715888977051, 52.6807532675943 ], [ 5.629441738128662, 52.68157281641395 ], [ 5.633561611175536, 52.67787822078012 ], [ 5.636715888977051, 52.6807532675943 ] ] ] } }, { "type": "Feature", "properties": {}, "geometry": { "type": "Polygon", "coordinates": [ [ [ 5.622982978820801, 52.68595649102906 ], [ 5.6201934814453125, 52.68429152697491 ], [ 5.628776550292969, 52.683719180920846 ], [ 5.622982978820801, 52.68595649102906 ] ] ] } } ]}\'')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# convert to sf object")]),t._v("\npolygons "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" geojson_sf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("polygons_string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# add any attribute as a workaround, empty simple features are not accepted")]),t._v("\npolygons"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("anAttribute "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# aggregate spatially")]),t._v("\ncube_s2_b8_agg "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("aggregate_spatial"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" geometries "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" polygons"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" At the time of writing this, empty simple features are not accepted and produce an error. To work around this issue, simply add a random attribute to the "),n("code",[t._v("sf")]),t._v(" object. Above we are assigning the (randomly chosen) values "),n("code",[t._v("4")]),t._v(" and "),n("code",[t._v("5")]),t._v(" to the two polygons in the collection.")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// define polygons as geojson")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" polygons "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"FeatureCollection"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"features"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Feature"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"geometry"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Polygon"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"coordinates"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.636715888977051")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6807532675943")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.629441738128662")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68157281641395")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.633561611175536")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.67787822078012")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.636715888977051")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.6807532675943")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Feature"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"geometry"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Polygon"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"coordinates"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.622982978820801")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68595649102906")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.6201934814453125")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68429152697491")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.628776550292969")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.683719180920846")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.622982978820801")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.68595649102906")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// aggregate spatial")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_b8_agg "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("aggregate_spatial")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" polygons"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mean")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("h3",{attrs:{id:"output-save-result"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#output-save-result"}},[t._v("#")]),t._v(" Output: "),n("code",[t._v("save_result")])]),t._v(" "),n("p",[t._v("To get a result, we first need to create a "),n("code",[t._v("save_result")]),t._v(" node, in which we state the desired output format and potential parameters, both dependent on the back-end you are connected to. The output formats and their parameters can e.g. be explored via the Web Editor along with available processes and collections.")]),t._v(" "),n("p",[t._v("We then proceed to send that job to the back-end, "),n("em",[t._v("without executing it")]),t._v(". Refer to the getting started guides on how to process results as batch or synchronous jobs. The way it is stated here allows us to log in to the Web Editor and look at, change, and execute the job from there.")]),t._v(" "),n("h4",{attrs:{id:"raster-formats-gtiff-netcdf"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#raster-formats-gtiff-netcdf"}},[t._v("#")]),t._v(" Raster Formats: GTiff, NetCDF")]),t._v(" "),n("p",[t._v("In the example, GeoTiff files are produced. Refer to the back-end for the available formats, options, and their correct naming. Check the "),n("a",{attrs:{href:"#raster-formats-png"}},[t._v("PNG section")]),t._v(" for passing options.")]),t._v(" "),n("p",[t._v("Different from the creation of a PNG image, the raster format doesn't need scaling and the original datacube can be downloaded as is. However, we need to be careful with the dimensionality of the datacube: How a 4+ - dimensional datacube is handled when converted to a raster format is back-end dependent. That is why we "),n("a",{attrs:{href:"#temporal-mean-reduce_dimension"}},[t._v("made sure")]),t._v(" that our cube would only contain one additional dimension, apart from the spatial "),n("code",[t._v("x")]),t._v(" and "),n("code",[t._v("y")]),t._v(".")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# save using save_result, give format as string")]),t._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8_red"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save_result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"GTiff"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send job to back-end, do not execute")]),t._v("\njob "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("send_job"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("title "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temporal_mean_as_GTiff_py"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use list_file_formats() to be able to choose from a list")]),t._v("\nformats "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list_file_formats"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# save using save_result, give format via list")]),t._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("save_result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8_red"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" format "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" formats"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("GTiff"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send job to back-end")]),t._v("\njob "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" create_job"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" title "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temporal_mean_as_GTiff_r"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// save using save_result, give fomat as string")]),t._v("\nresult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("save_result")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b8_red"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"GTiff"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// send job to back-end, but don't execute yet; set title")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" job "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("createJob")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temporal_mean_as_GTiff_js"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("h4",{attrs:{id:"raster-formats-png"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#raster-formats-png"}},[t._v("#")]),t._v(" Raster Formats: PNG")]),t._v(" "),n("p",[t._v("For a PNG output, we'll use the datacube with the bands 3, 4 and 8 (green, red and near-infrared) that we've been working on simultaneously with the datacube used above. As we have scaled the data down to 8bit using a "),n("a",{attrs:{href:"#scale-all-pixels-linearly-apply-linear_scale_range"}},[t._v("linear scale")]),t._v(", nothing stands in the way of downloading the data as PNG.")]),t._v(" "),n("p",[t._v("We want to produce a false-color composite highlighting the vegetation in red (as seen below the code). For that, we want to assign the infrared band ("),n("code",[t._v("B8")]),t._v(") to the red channel, the red band ("),n("code",[t._v("B4")]),t._v(") to the green channel and the green band ("),n("code",[t._v("B3")]),t._v(") to the blue channel. Some back-ends may offer to pass along this desired band order as it is shown below. Check with the back-end for available options.")]),t._v(" "),n("p",[t._v("If no options can be passed, handling of the bands for PNG output is internal and should be documented by the back-end. You might also be able to tell how this is done by how your PNG looks: As explained in the "),n("RouterLink",{attrs:{to:"/documentation/1.0/datacubes.html#dimensions"}},[t._v("datacube guide")]),t._v(", the order of the "),n("code",[t._v("bands")]),t._v(" dimension is defined when the values are loaded or altered (in our example: "),n("code",[t._v("filter_bands")]),t._v("). As we filter bands in the order "),n("code",[t._v('"B3", "B4", "B8"')]),t._v(" vegetation might be highlighted in blue, given that the back-end uses the input order for the RGB channels.")],1),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# save result cube as PNG")]),t._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348_red_lin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save_result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PNG"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" options "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"red"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B3"')]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send job to back-end")]),t._v("\njob "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("send_job"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("title "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temporal_mean_as_PNG_py"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("In python, options are passed as a dictionary")])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use list_file_formats() to be able to choose from a list")]),t._v("\nformats "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list_file_formats"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# save result as PNG")]),t._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("save_result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b348_red_lin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" format "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" formats"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("PNG"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                      options "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("red"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" green"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" blue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send job to back-end")]),t._v("\njob "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" create_job"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" title "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temporal_mean_as_PNG_r"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("In R, options are passed as a list.")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// save result as PNG")]),t._v("\nresult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("save_result")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b348_red_lin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PNG"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    red"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    green"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    blue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B3"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// send job to back-end")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" job "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("createJob")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temporal_mean_as_PNG_js"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("In JavaScript, options are passed as objects.")])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(266),alt:"Example PNG: false color composite highlighting vegetation in red."}}),t._v(" "),n("figcaption",[t._v("Image above: Example PNG output with the vegetation highlighted in red.")])]),t._v(" "),n("h4",{attrs:{id:"text-formats-json-csv"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#text-formats-json-csv"}},[t._v("#")]),t._v(" Text Formats: JSON, CSV")]),t._v(" "),n("p",[t._v("We can now save the timeseries in the "),n("a",{attrs:{href:"#spatial-aggregation-aggregate_spatial"}},[t._v("aggregated")]),t._v(" datacube as e.g. JSON.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# save result cube as JSON")]),t._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8_agg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save_result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"JSON"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send job to back-end")]),t._v("\njob "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("send_job"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("title "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timeseries_as_JSON_py"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use list_file_formats() to be able to choose from a list")]),t._v("\nformats "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list_file_formats"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# save result as JSON")]),t._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("save_result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8_agg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" format "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" formats"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# send job to back-end")]),t._v("\njob "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" create_job"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("graph "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" title "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timeseries_as_JSON_r"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" Because the R client rounds coordinates to four digits, slightly different results are received in comparison to the other clients.")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// save as CSV")]),t._v("\nresult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("save_result")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b8_agg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"JSON"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// send job to back-end")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" job "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("await")]),t._v(" con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("createJob")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timeseries_as_JSON_js"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("h2",{attrs:{id:"chapter-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#chapter-2"}},[t._v("#")]),t._v(" Chapter 2")]),t._v(" "),n("p",[t._v("In this second part of the cookbook, things are a bit less linear. We'll explore bandmath, masking and "),n("code",[t._v("apply_*")]),t._v(" functionality, only that these steps are less interconnected than in the first chapter.")]),t._v(" "),n("p",[t._v("As usual we'll load a collection to work with (Sentinel 2, bands "),n("code",[t._v("2")]),t._v(", "),n("code",[t._v("4")]),t._v(", "),n("code",[t._v("8")]),t._v(" and "),n("code",[t._v("SCL")]),t._v("). Let's call it "),n("code",[t._v("cube_s2")]),t._v(". We pre-select a time frame of which we know it only contains one Sentinel 2 scene, so that we're not bothered with multiple timesteps (the collection still contains a time dimension, but with only one timestep in it, so that it can be ignored). The extent has been chosen to provide results that are suitable to show the effect of the processes used, while being considerably small and thus fast to compute. If you want to minimize processing time you are of course free to use much smaller AOIs.")]),t._v(" "),n("p",[t._v("To be able to download and look at the results, refer to the "),n("a",{attrs:{href:"#raster-formats-gtiff-netcdf"}},[t._v("output section of chapter 1")]),t._v(". Most of the images in this tutorial were all downloaded as GTiff and plotted with R.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("pellworm "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"west"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.5464")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"south"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.4473")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"east"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.0724")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"north"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.5685")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-03-05"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-03-05"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ncube_s2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" con"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_collection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SENTINEL2_L2A_SENTINELHUB"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    spatial_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pellworm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    temporal_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    bands "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B02"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B04"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[t._v("pellworm "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("west "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.5464")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" south "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.4473")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" east "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.0724")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" north "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.5685")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-03-05"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-03-05"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ncube_s2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("load_collection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  id "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SENTINEL2_L2A_SENTINELHUB"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  spatial_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pellworm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  temporal_extent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  bands"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B02"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B04"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" pellworm "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"west"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8.5464")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"south"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.4473")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"east"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9.0724")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"north"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("54.5685")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" t "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-03-05"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2021-03-05"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("load_collection")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SENTINEL2_L2A_SENTINELHUB"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pellworm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B02"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B04"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(267),alt:"The AOI around Pellworm is shown as a false color RGB. RGB = red, nir and blue"}}),t._v(" "),n("figcaption",[t._v("This is a false color image of our area of interest for this chapter. The bands 4, 8 and 2 have been assigned to the RGB channels without any further processing. The surrounding area of the island Pellworm is shown at low tide.\n")])]),t._v(" "),n("h3",{attrs:{id:"bandmath"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#bandmath"}},[t._v("#")]),t._v(" Bandmath")]),t._v(" "),n("p",[t._v("Bandmath refers to computations that involve multiple bands, like indices (Normalized Difference Vegetation Index, Normalized Burn Ratio etc.).")]),t._v(" "),n("p",[t._v("In openEO, this goes along with using for example "),n("code",[t._v("reduce_dimension")]),t._v(" over the "),n("code",[t._v("bands")]),t._v(" dimension. In this process, a new pixel value is calculated from the values of different bands using a given formula (the actual bandmath), to then eliminate the "),n("code",[t._v("bands")]),t._v(" dimension alltogether. If e.g. a cube contains a "),n("code",[t._v("red")]),t._v(" and a "),n("code",[t._v("nir")]),t._v(" band in its "),n("code",[t._v("bands")]),t._v(" dimension and we reduce said dimension with a formula for the NDVI, that cube afterwards contains NDVI values, but no "),n("code",[t._v("bands")]),t._v(" dimension anymore.")]),t._v(" "),n("p",[t._v("In the following we'll observe a thorough explanation of how to calculate an NDVI. That section covers different ways (depending on the client) to set up such a process in openEO. Afterwards, we'll see how an EVI is computed in a quicker, less thorough example.")]),t._v(" "),n("h4",{attrs:{id:"example-1-ndvi"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#example-1-ndvi"}},[t._v("#")]),t._v(" Example 1: NDVI")]),t._v(" "),n("p",[t._v("As mentioned above, bandmath is about reducing the "),n("code",[t._v("bands")]),t._v(" dimension with a child process (a formula) that gives us the desired output. In "),n("a",{attrs:{href:"#chapter-1"}},[t._v("chapter one")]),t._v(", we already saw different ways of defining a child process: a) We learned how to use a simple "),n("code",[t._v("mean")]),t._v(" to "),n("RouterLink",{attrs:{to:"/documentation/1.0/cookbook/#temporal-mean-reduce-dimension"}},[t._v("reduce the time dimension")]),t._v(", and b) we saw how to access and use the openEO defined "),n("code",[t._v("linear_scale_range")]),t._v(" function "),n("RouterLink",{attrs:{to:"/documentation/1.0/cookbook/#scale-all-pixels-linearly-apply-linear-scale-range"}},[t._v("to scale all pixels linearly")]),t._v(".")],1),t._v(" "),n("p",[t._v("In this chapter, we'll reiterate these techniques and discuss some subtleties and alternatives. It is up to you to choose one that works best. Special to the NDVI is, given that it is "),n("em",[t._v("the")]),t._v(" most common use case, that openEO has predefined processes that cover the math for us and only need to be given the correct input. There even is a function "),n("code",[t._v("ndvi")]),t._v(" that masks all details and only takes a datacube and the bandnames as input. Further down we'll dig into what this "),n("code",[t._v("ndvi")]),t._v(" process actually masks, how we can reproduce that manually, and thus how we could formulate other bandmath functions, apart from an NDVI.")]),t._v(" "),n("p",[t._v("By using the openEO defined "),n("strong",[n("code",[t._v("ndvi")]),t._v(" function")]),t._v(", calculating an NDVI becomes pretty straightforward. The process can detect the red and near-infrared band based on metadata and doesn't need bandname input (but band names can be passed to calculate other normalized differences). Also, by supplying the optional parameter "),n("code",[t._v("target_band")]),t._v(" we can decide if we want to get a reduced cube with NDVI values and no "),n("code",[t._v("bands")]),t._v(" dimension as result, or if we want to append the new NDVI band to the existing bands of our input cube. If we choose the latter, we only need to supply a name for that new NDVI band.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("cube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or name bands explicitly + append the result band to the existing cube")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# cube_s2_ndvi_bands = cube_s2.ndvi(nir = "B08", red = "B04", target_band = "NDVI")')]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[t._v("cube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or name bands explicitly + append the result band to the existing cube")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# cube_s2_nvdi_bands <- p$ndvi(data = cube_s2, nir = "B08", red = "B04", target_band = "NDVI")')]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("cube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("ndvi")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// or name bands explicitly + append the result band to the existing cube")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// cube_s2_ndvi_bands = builder.ndvi(cube_s2, "B08", "B04", "NDVI")')]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("p",[t._v("For the purpose of understanding, we'll stick with our NDVI example to explore different ways of defining bandmath in openEO. That gives you the knowledge to define other processes, not just NDVIs. The first method is available in all clients: "),n("strong",[t._v("Defining a function")]),t._v(" and passing it to a process, e.g. "),n("code",[t._v("reduce_dimension")]),t._v(". If available, other possibilities are discussed afterwards.")]),t._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[t._v("Important: Check Band Indices and Bandnames!")]),t._v(" "),n("p",[t._v("Be careful when handling the names or array indices of bands. While names differ across back-ends, indices can be mixed up easily when some other band is deleted from the input collection. Python and JavaScript have 0-based indices, R indices are 1-based. So double check which bands you're actually using.")])]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# necessary imports")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" openeo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("processes "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" array_element"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normalized_difference\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define an NDVI function")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("ndvi_function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    B04 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" array_element"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# array_element takes either an index ..")]),t._v("\n    B08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" array_element"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or a label")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ndvi = (B08 - B04) / (B08 + B04) # implement NDVI as formula ..")]),t._v("\n    ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" normalized_difference"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B08"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" B04"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# or use the openEO "normalized_difference" process')]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ndvi\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# supply the defined function to a reduce_dimension process, set dimension = "bands"')]),t._v("\ncube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ndvi_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("What we see above:")]),t._v(" "),n("ul",[n("li",[t._v("access specific bands inside the child process: "),n("code",[t._v("array_element")]),t._v(" (supply data and index/label)")]),t._v(" "),n("li",[t._v("call openEO defined functions inside the child process by importing it: "),n("code",[t._v("from openeo.processes import normalized_difference")])]),t._v(" "),n("li",[t._v("write math as formula inside the child process: "),n("code",[t._v("ndvi = (B08 - B04) / (B08 + B04)")])])]),t._v(" "),n("p",[t._v("The python client also holds a second possibility to do the above. It has a "),n("strong",[t._v("function "),n("code",[t._v("band")])]),t._v(" that does "),n("code",[t._v("array_element")]),t._v(" and "),n("code",[t._v('reduce_dimension(dimension = "bands")')]),t._v(" for us. When using it, we can type out the NDVI formula right in the script (since "),n("code",[t._v(".band")]),t._v(" reduced the cube for us).")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("B04 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("band"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B04"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nB08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("band"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ncube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" B04"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" B04"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# type math formula")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define an NDVI function")]),t._v("\nndvi_function "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  B04 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we can supply an index (1-based in R) ..")]),t._v("\n  B08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or a label")]),t._v("\n  \n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ndvi <- (B08 - B04) / (B08 + B04) # implement NDVI as formula ..")]),t._v("\n  ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("normalized_difference"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B08"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" B04"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# or use the openEO "normalized_difference" process')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ndvi <- p$normalized_difference(data[2], data[3]) # or shorten all in one line")]),t._v("\n\n  return"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# supply the defined function to a reduce_dimension process, set dimension = "bands"')]),t._v("\ncube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ndvi_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("What we see above:")]),t._v(" "),n("ul",[n("li",[t._v("access specific bands inside the child process by using array subset: "),n("code",[t._v("data[index]")]),t._v(" or "),n("code",[t._v('data["bandname"]')])]),t._v(" "),n("li",[t._v("call openEO defined functions inside the child process by calling it via the "),n("code",[t._v("p")]),t._v(" processes environment: "),n("code",[t._v("p$normalized_difference")])]),t._v(" "),n("li",[t._v("write math as formulas inside the child process: "),n("code",[t._v("ndvi <- (B08 - B04) / (B08 + B04)")])])]),t._v(" "),n("p",[t._v("In R, there are no other ways to define a child process than through defining a function as seen above.")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// define NDVI function")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("ndvi_function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("B04")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// use array operator to extract bands")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("B08")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// or supply label")]),t._v("\n\n    ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("normalized_difference")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("B08")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("B04")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// use "this" to access openEO processes inside this function')]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ndvi = this.normalized_difference(data["B08"], data["B04"]) // or shorten it all into one line')]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ndvi\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// supply the defined function to a reduce_dimension process, set dimension = "bands"')]),t._v("\ncube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ndvi_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("What we see above:")]),t._v(" "),n("ul",[n("li",[t._v("access specific bands inside the child process by using array subset: "),n("code",[t._v("data[index]")]),t._v(" or "),n("code",[t._v('data["bandname"]')])]),t._v(" "),n("li",[t._v("call openEO defined functions inside the child process by calling it via "),n("code",[t._v("this")])])]),t._v(" "),n("p",[t._v("We note that JavaScript doesn't support just typing out math functions as R and Python do. But the JS client has another, even simpler way of defining quick bandmath: "),n("strong",[t._v("using "),n("code",[t._v("new Formula")])]),t._v(".")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// using "New Formula()", both $index and $label are valid as seen here, $1 refers to B04')]),t._v("\ncube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Formula")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"($B08 - $1) / ($B08 + $1)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("We see that using "),n("code",[t._v('new Formula("")')]),t._v(" is much faster than defining a whole child process. We use "),n("code",[t._v("$")]),t._v(" to access bands (works with "),n("code",[t._v("$indices")]),t._v(" or "),n("code",[t._v("$bandnames")]),t._v("). If we want to use openEO defined processes, there's also the "),n("strong",[t._v("arrow function")]),t._v(" to still be able to do that in-line.")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// using an arrow function to call openeo process "normalized_difference"')]),t._v("\ncube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("normalized_difference")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("In an arrow function, we can use array subsets again.")]),t._v(" "),n("p",[t._v("To sum up: Although "),n("code",[t._v("new Formula")]),t._v(" is probably the most straightforward way of calculating an NDVI, it is up to you to decide on a method that suits your use-case.")])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(268),alt:"NDVI image of the AOI"}}),t._v(" "),n("figcaption",[t._v("A correctly calculated NDVI would look as displayed here (scaled linearly).")])]),t._v(" "),n("h4",{attrs:{id:"example-2-evi"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#example-2-evi"}},[t._v("#")]),t._v(" Example 2: EVI")]),t._v(" "),n("p",[t._v("The formula for the Enhanced Vegetation Index is a bit more complicated than the NDVI one and contains constants. But we also don't necessarily need an openEO defined function and can concentrate on implementing a more complex formula. Here's the most efficient way to do this, per client.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# extract and reduce all bands via "band"')]),t._v("\nB02 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("band"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B02"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nB04 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("band"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B04"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nB08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("band"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# write formula")]),t._v("\ncube_s2_evi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.5")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" B04"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("B08 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6.0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" B04 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7.5")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" B02"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# in R, there's no shorter way to define bandmath")]),t._v("\nevi_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  b2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  b4 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  return"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.5")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" b4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" b4 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7.5")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" b2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# reduce_dimension bands with the defined formula")]),t._v("\ncube_s2_evi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" evi_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// "new Formula" is the quickest way to provide a bandmath formula')]),t._v("\ncube_s2_evi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Formula")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"(2.5 * ($B08 - $B04)) / (($B08 + 6 * $B04 - 7.5 * $B02) + 1)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("h3",{attrs:{id:"masks-mask"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#masks-mask"}},[t._v("#")]),t._v(" Masks: "),n("code",[t._v("mask")])]),t._v(" "),n("p",[t._v("Masking generally refers to excluding (or replacing) specific areas from an image. This is usually done by providing a boolean mask that detemines which pixels to replace with a no-data value, and which to leave as they are. In the following we will consider two cases: a) Creating a mask from classification classes and b) creating a mask by thresholding an image.")]),t._v(" "),n("h4",{attrs:{id:"mask-out-specific-values"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#mask-out-specific-values"}},[t._v("#")]),t._v(" Mask Out Specific Values")]),t._v(" "),n("p",[t._v("In some cases we want to mask our data with other data. A common example is to mask out clouds, which optical satellites can not see through. Some Sentinel 2 collections provide the "),n("code",[t._v("SCL")]),t._v(" classification band (see the table of classes "),n("a",{attrs:{href:"https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm",target:"_blank",rel:"noopener noreferrer"}},[t._v("at the bottom here"),n("OutboundLink")],1),t._v("), providing a representation coded into land cover classes. In this classification, vegetation is coded as "),n("code",[t._v("4")]),t._v(" and non-vegetation as "),n("code",[t._v("5")]),t._v(", while e.g. clouds are coded as "),n("code",[t._v("8")]),t._v(" to "),n("code",[t._v("10")]),t._v(".")]),t._v(" "),n("p",[t._v("In the following, we're building a mask using some logical operations as a child process while reducing the dimension "),n("code",[t._v("bands")]),t._v(". As explained at "),n("a",{attrs:{href:"#example-1-ndvi"}},[t._v("Example 1: NDVI")]),t._v(" this is done to be left with a cube that has no dimension "),n("code",[t._v("bands")]),t._v(". In R and JavaScript, we write a function "),n("code",[t._v("filter_")]),t._v(" that turns the values of the "),n("code",[t._v("SCL")]),t._v(" band into "),n("code",[t._v("0")]),t._v("s (for (non-) vegetation) and "),n("code",[t._v("1")]),t._v("s (for all others), and ignores all other bands. During "),n("code",[t._v("mask")]),t._v(", all "),n("code",[t._v("1")]),t._v("s (i.e. "),n("code",[t._v("TRUE")]),t._v(") pixels will be replaced, and as we don't define a replacement they will simply be set to "),n("code",[t._v("null")]),t._v(". In Python, in-line logical operations can be used.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get classification band")]),t._v("\nSCL "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("band"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we want to mask all other values, so NOT (4 OR 5)")]),t._v("\ncube_s2_mask "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("SCL "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("SCL "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# masking")]),t._v("\ncube_s2_masked "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define filter function to create mask")]),t._v("\nfilter_function "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  vegetation "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("eq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# vegetation is 4")]),t._v("\n  non_vegetation "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("eq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# non-vegetation is 5")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we want to mask all other values, so NOT (4 OR 5)")]),t._v("\n  return"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("not"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("or"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vegetation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" non_vegetation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create mask by reducing bands with our defined formula")]),t._v("\ncube_s2_mask "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("reduce_dimension"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" filter_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mask the NDVI data")]),t._v("\ncube_s2_masked "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cube_s2_mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// filter classification layer")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("filter_function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  vegetation "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("eq")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// vegetation is 4")]),t._v("\n  non_vegetation "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("eq")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SCL"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// non-vegetation is 5")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// we want to mask all other values, so NOT (4 OR 5)")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("not")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("or")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vegetation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" non_vegetation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// create mask by reducing bands")]),t._v("\ncube_s2_mask "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce_dimension")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filter_function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bands"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// mask")]),t._v("\ncube_s2_masked "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mask")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cube_s2_mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("p",[t._v('As with all functionality there are differences between back-ends. If this first example "Mask Out Specific Values" doesn\'t work for you, that could be because we are trying to apply a mask (a cube with dimensions '),n("code",[t._v("x")]),t._v(", "),n("code",[t._v("y")]),t._v(", "),n("code",[t._v("t")]),t._v(") to the input data (a cube with dimensions "),n("code",[t._v("x")]),t._v(", "),n("code",[t._v("y")]),t._v(", "),n("code",[t._v("t")]),t._v(", "),n("code",[t._v("bands")]),t._v(") and thus, cubes with different dimensionality. If you encounter such a problem, try applying the first mask to the NDVI cube (with dimensions "),n("code",[t._v("x")]),t._v(", "),n("code",[t._v("y")]),t._v(", "),n("code",[t._v("t")]),t._v(') as it is shown in the second example "Thresholds".')]),t._v(" "),n("h4",{attrs:{id:"thresholds"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#thresholds"}},[t._v("#")]),t._v(" Thresholds")]),t._v(" "),n("p",[t._v("In this scenario we want an image that contains all NDVI values above 0.3, and holds no-data values otherwise. This could be useful to have a look at the vegetation in the area, without being distracted by all other NDVI values. For this example we reuse the NDVI cube "),n("code",[t._v("cube_s2_ndvi")]),t._v(" that was calculated in the "),n("a",{attrs:{href:"#example-1-ndvi"}},[t._v("NDVI bandmath-example")]),t._v(", thus for this to work you must include said code into your script.")]),t._v(" "),n("p",[t._v("If you look closely, you'll notice that this time we're not using "),n("code",[t._v("reduce_dimension")]),t._v(" to construct our masking cube (in contrast to "),n("a",{attrs:{href:"#mask-out-specific-values"}},[t._v("Mask out Specific Values")]),t._v("). In R and JavaScript we use "),n("code",[t._v("apply")]),t._v(" instead, and in the python client no "),n("code",[t._v(".band()")]),t._v(" is necessary anymore. This is because when we were masking using specific values of the band "),n("code",[t._v("SCL")]),t._v(", we were using the "),n("code",[t._v("cube_s2")]),t._v(" (with the bands "),n("code",[t._v("B02")]),t._v(", "),n("code",[t._v("B04")]),t._v(", "),n("code",[t._v("B08")]),t._v(" and "),n("code",[t._v("SCL")]),t._v(") as input. We then reduced the "),n("code",[t._v("bands")]),t._v(" dimension by writing and passing the function "),n("code",[t._v("filter_")]),t._v(", which returned a cube that had no "),n("code",[t._v("bands")]),t._v(" dimension anymore but "),n("code",[t._v("1")]),t._v("s and "),n("code",[t._v("0")]),t._v("s according to what we wanted to mask.")]),t._v(" "),n("p",[t._v("Here, we are making a mask out of the "),n("code",[t._v("cube_s2_ndvi")]),t._v(", a cube that had its "),n("code",[t._v("band")]),t._v(" dimension already reduced when the NDVI was calculated. To turn its values into "),n("code",[t._v("1")]),t._v("s and "),n("code",[t._v("0")]),t._v("s, we only need to "),n("code",[t._v("apply")]),t._v(" a threshold function. For this we utilize the openEO defined function "),n("code",[t._v("lt")]),t._v(' ("less than"). As usual the clients expose different ways of getting to that function, one of which is shown below.')]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create mask that is TRUE for NDVI < 0.3")]),t._v("\nndvi_threshold "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_ndvi "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# apply mask to NDVI")]),t._v("\ncube_s2_ndvi_masked "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ndvi_threshold"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[t._v("threshold_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create mask that is TRUE for NDVI < 0.3")]),t._v("\n  threshold "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("lt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  return"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("threshold"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# apply the threshold to the NDVI cube")]),t._v("\nndvi_threshold "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" process "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" threshold_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mask the NDVI cube with the calculated mask")]),t._v("\ncube_s2_ndvi_masked "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("mask"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ndvi_threshold"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// create mask that is TRUE for NDVI < 0.3 via an arrow function")]),t._v("\nndvi_threshold "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("builder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("lt")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// apply mask to NDVI cube")]),t._v("\ncube_s2_ndvi_masked "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mask")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_ndvi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ndvi_threshold"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(269),alt:"The NDVI with a threshold of 0.3 applied"}}),t._v(" "),n("figcaption",[t._v("Applying the above described treshold to the NDVI yields this result. Water and artificial surfaces are mostly masked from the image.")])]),t._v(" "),n("h3",{attrs:{id:"pixel-operations-apply"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#pixel-operations-apply"}},[t._v("#")]),t._v(" Pixel Operations: "),n("code",[t._v("apply")])]),t._v(" "),n("p",[t._v("As we remember from the "),n("RouterLink",{attrs:{to:"/documentation/1.0/datacubes.html#apply"}},[t._v("datacube guide")]),t._v(", unary processes take only the pixel itself into account when calculating new pixel values. We can implement that with the "),n("code",[t._v("apply")]),t._v(" function and a child process that is in charge of modifying the pixel values. In our first example, that will be the square root. The openEO function is called "),n("code",[t._v("sqrt")]),t._v(". In the following we'll see how to pass it to the "),n("code",[t._v("apply")]),t._v(" process.")],1),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# pass unary child process as string")]),t._v("\ncube_s2_sqrt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sqrt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# pass unary child process as a function, call "sqrt" from openEO processes "p"')]),t._v("\ncube_s2_sqrt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" return"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// pass unary child process via arrow function")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_sqrt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("builder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sqrt")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("p",[t._v("Let's say we're not looking at optical but SAR imagery. Depending on the collection held by the back-end, this data could already be log-scaled. In case it isn't, we may want to transform our data from intensity values to db. This formula is a bit more complicated: 10 * log"),n("sub",[t._v("10")]),t._v("(x). So we'll need a multiplication (by 10) and a "),n("code",[t._v("log")]),t._v(" process (to the "),n("code",[t._v("base")]),t._v(" 10).")]),t._v(" "),n("p",[t._v("Prior to applying the following code, we must load a collection containing SAR intensity data (e.g. Sentinel 1 GRD product).")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# import the defined openEO process")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" openeo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("processes "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" log\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define a child process")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log_")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" log"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# supply that function to the "apply" call')]),t._v("\ncube_s1_log10 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("log_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# call multiply, log functions from "p"')]),t._v("\ncube_s1_log10 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("multiply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("log"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// use openEO "log", "multiply" via arrow function')]),t._v("\ncube_s1_log10 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("builder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("multiply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(270),alt:"The AOI image is split into two parts: The upper part depicts SAR data with some very bright and many very dark pixels, the lower part is more balanced."}}),t._v(" "),n("figcaption",[t._v("Here we see the effect of transforming intensity data to db: Both parts of the image are linearly scaled, but only the lower part has been log-transformed. It makes the interpretation much easier because image pixels take on less 'extreme' values.")])]),t._v(" "),n("h3",{attrs:{id:"image-kernels-apply-kernel"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#image-kernels-apply-kernel"}},[t._v("#")]),t._v(" Image Kernels: "),n("code",[t._v("apply_kernel")])]),t._v(" "),n("p",[t._v("The process "),n("code",[t._v("apply_kernel")]),t._v(" takes an array of weights that is used as a moving window to calculate new pixel values. This is often used to smooth or sharped the image (e.g. Gaussian blur or highpass filter, respectively). Here, we show two Sobel edge detection kernels (both vertical and horizontal) and a highpass filter.")]),t._v(" "),n("p",[t._v("We'll only consider band 8 to shorten computation time.")]),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("cube_s2_b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter_bands"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[t._v("cube_s2_b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("filter_bands"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("cube_s2_b8 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter_bands")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("p",[t._v("Throughout all clients we can define the kernel as an array of arrays, of which the inner arrays represent lines ("),n("code",[t._v("x")]),t._v(") and the outer arrays columns ("),n("code",[t._v("y")]),t._v("). This means that by adding a line break after each inner array, a true representation of the kernel can be created (see "),n("code",[t._v("highpass")]),t._v(" in Python or JavaScript tab).")]),t._v(" "),n("p",[t._v("The parameters "),n("code",[t._v("factor")]),t._v(" and "),n("code",[t._v("border")]),t._v(" are not needed here and are left out to fall back to default. "),n("code",[t._v("factor")]),t._v(" (default "),n("code",[t._v("1")]),t._v(") is multiplied with each pixel after the focal operation, while "),n("code",[t._v("border")]),t._v(" (default "),n("code",[t._v("0")]),t._v(") defines how overlaps between the kernel and the image borders are handled (should pixel values be mirrored, replicated or simply set to 0?, see "),n("RouterLink",{attrs:{to:"/documentation/1.0/processes.html#apply_kernel"}},[n("code",[t._v("apply_kernel")])]),t._v(").")],1),t._v(" "),n("CodeSwitcher",{scopedSlots:t._u([{key:"py",fn:function(){return[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we can pass a kernel as an array of arrays")]),t._v("\nsobel_vertical "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# e.g. 3x3 edge detection")]),t._v("\nsobel_horizontal "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nhighpass "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or 5x5 highpass filter")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# apply to cube")]),t._v("\ncube_s2_highpass "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply_kernel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("highpass"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0},{key:"r",fn:function(){return[n("div",{staticClass:"language-r extra-class"},[n("pre",{pre:!0,attrs:{class:"language-r"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# we can pass a kernel as an array of arrays")]),t._v("\nsobel_vertical "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" matrix"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nrow "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" byrow "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nsobel_horizontal "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" matrix"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nrow "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# e.g. 3x3 edge detection")]),t._v("\n\nhighpass_vector "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rep"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rep"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nhighpass "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" matrix"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("highpass_vector"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nrow "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or 5x5 highpass filter")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# apply to cube")]),t._v("\ncube_s2_b8_highpass "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("apply_kernel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kernel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" highpass"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Note:")]),t._v(" As of now, there seems to be the bug that the parameter "),n("code",[t._v("border")]),t._v(" is wrongfully set as a string by the R client (see "),n("a",{attrs:{href:"https://github.com/Open-EO/openeo-r-client/issues/65",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue on github"),n("OutboundLink")],1),t._v("). If you're executing this job via the "),n("a",{attrs:{href:"https://editor.openeo.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Web Editor"),n("OutboundLink")],1),t._v(", you can change this in the process graph itself: Change "),n("code",[t._v('"border": "0",')]),t._v(" to "),n("code",[t._v('"border": 0,')]),t._v(".")])]},proxy:!0},{key:"js",fn:function(){return[n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// we can pass a kernel as an array of arrays")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" sobel_vertical "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// e.g. 3x3 edge detection")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" sobel_horizontal "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" highpass "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// or 5x5 highpass filter")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// apply to cube")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" cube_s2_highpass "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("apply_kernel")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cube_s2_b8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" highpass"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]},proxy:!0}])}),t._v(" "),n("figure",[n("img",{attrs:{src:a(271),alt:"A combined edge detection RGB. Sobel vertical and horizontal are displayed as red and green, a 5x5 highpass filter is displayed as blue."}}),t._v(" "),n("figcaption",[t._v("Above a combined edge detection RGB can be seen. Sobel 3x3 vertical and horizontal edge detections are displayed as red and green, and a 5x5 highpass filter is displayed as blue. For this, all kernels in the code block above were applied and the sucessive cubes were merged afterwards.")])]),t._v(" "),n("p",[t._v("Pre-defined processes ("),n("code",[t._v("median")]),t._v(", "),n("code",[t._v("max")]),t._v(", "),n("code",[t._v("sd")]),t._v(" etc.) can be applied to spatial, temporal or even spatio-temporal neighbourhoods with "),n("code",[t._v("apply_neighborhood")]),t._v(". Due to lack of implementation by back-ends, this is not covered at this point. Some notes on the process "),n("code",[t._v("apply_dimension")]),t._v(" will follow soon.")]),t._v(" "),n("h2",{attrs:{id:"endnote"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#endnote"}},[t._v("#")]),t._v(" Endnote")]),t._v(" "),n("p",[t._v("You have "),n("strong",[t._v("feedback or")]),t._v(" noticed an "),n("strong",[t._v("error")]),t._v("? Feel free to open an issue in the "),n("a",{attrs:{href:"https://github.com/Open-EO/openeo.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("github repository"),n("OutboundLink")],1),t._v(" or use the "),n("a",{attrs:{href:"https://openeo.org/contact.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("other communication channels"),n("OutboundLink")],1)])],1)}),[],!1,null,null,null);s.default=e.exports}}]);